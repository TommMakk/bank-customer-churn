{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "qcs443mtk27v7x64a4vv",
   "authorId": "5216156492407",
   "authorName": "TOGEMOGE",
   "authorEmail": "tommi_makela@outlook.com",
   "sessionId": "be89d0c3-6e1b-452a-a676-3e6b32a9df45",
   "lastEditTime": 1763573154904
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "MInitiateConnection",
    "collapsed": false
   },
   "source": "# Setup Snowpark Session and Load Data\n"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "InitiateConnection"
   },
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.preprocessing import OrdinalEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import PartialDependenceDisplay\nimport shap\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\nfrom snowflake.ml.registry import Registry\n\n# Automatically get the current Snowflake session (no credentials needed)\nsession = Session.builder.getOrCreate()\n# Select your working database and schema\nsession.sql(\"USE DATABASE churn_modeling_db\").collect()\nsession.sql(\"USE SCHEMA churn_modeling_schema\").collect()\n\n# Load data from the table created earlier\ndf = session.table(\"customer_data\")\n\n# Show a sample\ndf.show(10)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e87f0d44-d889-4e3c-86d9-05c27a7f73bd",
   "metadata": {
    "name": "MGetFeatureView",
    "collapsed": false
   },
   "source": "# Load Feature View"
  },
  {
   "cell_type": "code",
   "id": "6a25626b-36dc-4db0-a0a2-69ed7ca7940b",
   "metadata": {
    "language": "python",
    "name": "GetFeatureView"
   },
   "outputs": [],
   "source": "# Initialize the Feature Store\nfs = FeatureStore(\n    session=session,\n    database=\"CHURN_MODELING_DB\",\n    name=\"CHURN_FEATURE_STORE\",\n    default_warehouse=\"CHURN_WAREHOUSE\",\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n)\n\n# Get the FeatureView\nfv = fs.get_feature_view(\"customer_churn_features_v2\", version=\"v1\")\n\n# Use the underlying Snowpark DataFrame\nfv_df = fv.feature_df\n\n# Show first 5 rows\nfv_df.show(5)\n\n# Select columns\nfv_df.select(\"CLIENTID\", \"CREDITSCORE\", \"CHURNED\").show(5)\n\n# Filter\nfv_df.filter(fv_df[\"CHURNED\"] == 1).show(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd469dcb-b6a8-4733-aef4-c3f841bf6c26",
   "metadata": {
    "name": "MFeatureEngineering",
    "collapsed": false
   },
   "source": "# Feature Engineering"
  },
  {
   "cell_type": "code",
   "id": "d891649e-a4d2-43e8-a872-d3e7b7f54f31",
   "metadata": {
    "language": "python",
    "name": "FeatureEngineering"
   },
   "outputs": [],
   "source": "# Preprocessing steps\nencoder = OrdinalEncoder(\n    input_cols=[\"GENDER\", \"GEOGRAPHY\"],\n    output_cols=[\"GENDER_ENCODED\", \"GEOGRAPHY_ENCODED\"]\n)\n\nscaler = StandardScaler(\n    input_cols=[\n        \"CREDITSCORE\", \"AGE\", \"GRADE\", \"ACCOUNTBALANCE\",\n        \"PRODUCTCOUNT\", \"OWNSCREDITCARD\", \"ISACTIVE\", \"SALARYESTIMATED\"\n    ],\n    output_cols=[\n        \"CREDITSCORE_S\", \"AGE_S\", \"GRADE_S\", \"ACCOUNTBALANCE_S\",\n        \"PRODUCTCOUNT_S\", \"OWNSCREDITCARD_S\", \"ISACTIVE_S\", \"SALARYESTIMATED_S\"\n    ]\n)\n\n# Select relevant columns from Snowpark DataFrame\ndf_for_pipeline = df.select(\n    \"GENDER\", \"GEOGRAPHY\", \"CREDITSCORE\", \"AGE\", \"GRADE\", \"ACCOUNTBALANCE\",\n    \"PRODUCTCOUNT\", \"OWNSCREDITCARD\", \"ISACTIVE\", \"SALARYESTIMATED\", \"CHURNED\"\n)\n\n# Fit preprocessing pipeline\npipeline = Pipeline(steps=[(\"encoder\", encoder), (\"scaler\", scaler)])\nfitted_pipeline = pipeline.fit(df_for_pipeline)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acdfc71d-d3c8-442c-9261-49cf190471b2",
   "metadata": {
    "name": "MTrainTest",
    "collapsed": false
   },
   "source": "# Split Train/Test"
  },
  {
   "cell_type": "code",
   "id": "bab7cee7-654f-48d6-9b4a-61de2b0a5400",
   "metadata": {
    "language": "python",
    "name": "TrainTest"
   },
   "outputs": [],
   "source": "# Transform data\ntransformed_df = fitted_pipeline.transform(df_for_pipeline)\n\n# Convert to pandas for scikit-learn\nfeature_cols = [\n    \"CREDITSCORE_S\", \"AGE_S\", \"GRADE_S\", \"ACCOUNTBALANCE_S\",\n    \"PRODUCTCOUNT_S\", \"OWNSCREDITCARD_S\", \"ISACTIVE_S\", \"SALARYESTIMATED_S\",\n    \"GENDER_ENCODED\", \"GEOGRAPHY_ENCODED\"\n]\nX = transformed_df.select(feature_cols).to_pandas()\ny = transformed_df.select(\"CHURNED\").to_pandas().values.ravel()\n\n# Split into train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7186178f-d48a-48e3-b72a-09c4f8f85133",
   "metadata": {
    "name": "MTrainModel",
    "collapsed": false
   },
   "source": "# Train XGBClassifier\nRequires to install *snowflake-ml-python* and *XGBClassifier* libraries to snowflake notebook"
  },
  {
   "cell_type": "code",
   "id": "dae4bba7-2f0e-4b10-97fb-d8592de01415",
   "metadata": {
    "language": "python",
    "name": "TrainModel"
   },
   "outputs": [],
   "source": "# Define parameters\nxgb_params = {\n    \"n_estimators\": 300,\n    \"learning_rate\": 0.1,\n    \"max_depth\": 6,\n    \"eval_metric\": \"logloss\",\n    \"use_label_encoder\": False\n}\n\n# Train\nmodel = XGBClassifier(**xgb_params)\nmodel.fit(X_train, y_train)\n\nprint(\"XGBoost trained successfully (Snowflake preprocessing â†’ scikit-learn workflow)\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cc92e25-8fd4-4299-811c-f41369016167",
   "metadata": {
    "name": "MSaveToModelRegistry",
    "collapsed": false
   },
   "source": "# Save Model to Model Registry"
  },
  {
   "cell_type": "code",
   "id": "6513c52d-e2af-4428-83dc-80240c02502f",
   "metadata": {
    "language": "python",
    "name": "SaveToModelRegistry"
   },
   "outputs": [],
   "source": "# Initialize registry\nregistry = Registry(session=session)\n\n# Compute metrics\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:, 1]\n\nmetrics = {\n    \"accuracy\": float(accuracy_score(y_test, y_pred)),\n    \"roc_auc\": float(roc_auc_score(y_test, y_prob))\n}\n\n# Safe logging: if version exists, skip or auto-generate\ntry:\n    model_version = registry.log_model(\n        model=model,\n        model_name=\"CHURN_XGB_MODEL\",\n        version_name=\"v1\",  # optional\n        metrics=metrics,\n        sample_input_data=pd.DataFrame(X_test).head(10)\n    )\n    print(\"Model logged to registry:\", model_version)\nexcept ValueError as e:\n    if \"already existed\" in str(e):\n        print(\"Model version already exists, skipping logging.\")\n    else:\n        raise  # re-raise other unexpected errors\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a7a50c45-9fb2-4e3c-9050-3a0aef6201a1",
   "metadata": {
    "name": "MInterpret",
    "collapsed": false
   },
   "source": "# Inspect Feature Importance & interpret results"
  },
  {
   "cell_type": "code",
   "id": "366e07b0-db95-48d1-84b6-f9f6cce21b88",
   "metadata": {
    "language": "python",
    "name": "InterpretFeatureImportance"
   },
   "outputs": [],
   "source": "# Initialize registry\nregistry = Registry(session=session)\n\n# Retrieve the model object (Model) by name\nm = registry.get_model(model_name=\"CHURN_XGB_MODEL\")\n\n# Then select a specific version\nmv = m.version(\"v1\")  # or mv = m.default if you want the default version\n\n# Load the actual model object from the version\nmodel = mv.load()\n\n# Now you can do feature importance\nfeature_cols = [\n    \"CREDITSCORE_S\", \"AGE_S\", \"GRADE_S\", \"ACCOUNTBALANCE_S\",\n    \"PRODUCTCOUNT_S\", \"OWNSCREDITCARD_S\", \"ISACTIVE_S\", \"SALARYESTIMATED_S\",\n    \"GENDER_ENCODED\", \"GEOGRAPHY_ENCODED\"\n]\n\nimportance_df = pd.DataFrame({\n    \"Feature\": feature_cols,\n    \"Importance\": model.feature_importances_\n}).sort_values(by=\"Importance\", ascending=False)\n\nprint(importance_df)\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nplt.figure(figsize=(10,6))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\nplt.gca().invert_yaxis()\nplt.title(\"Feature Importance\")\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0cd67547-4300-46b3-88d8-76a3fc69c233",
   "metadata": {
    "language": "python",
    "name": "ConfusionMatrixRocAuc"
   },
   "outputs": [],
   "source": "# ---------------------------\n# Model Performance Charts\n# ---------------------------\n\n# Predictions\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# Metrics\naccuracy = accuracy_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_prob)\n\nprint(f\"Accuracy: {accuracy:.2f}, ROC-AUC: {roc_auc:.2f}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\ncm_df = pd.DataFrame(cm, index=[\"Actual No Churn\", \"Actual Churn\"],\n                     columns=[\"Pred No Churn\", \"Pred Churn\"])\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Optional: ROC Curve\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, label=f\"ROC-AUC = {roc_auc:.2f}\")\nplt.plot([0,1],[0,1],'--', color='grey')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.show()\n\n\n# ---------------------------\n# Feature Importance\n# ---------------------------\n\nimportance_df = pd.DataFrame({\n    \"Feature\": feature_cols,\n    \"Importance\": model.feature_importances_\n}).sort_values(by=\"Importance\", ascending=True)\n\nplt.figure(figsize=(8,6))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color=\"skyblue\")\nplt.title(\"Feature Importance\")\nplt.xlabel(\"Importance\")\nplt.show()\n\n\n# ---------------------------\n# Risk Segmentation\n# ---------------------------\n\n# Predicted churn probability\nrisk_df = pd.DataFrame({\n    \"CustomerID\": X_test.index,\n    \"Churn_Prob\": y_prob\n})\n\n# Define risk bins\nbins = [0, 0.3, 0.6, 1]\nlabels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\nrisk_df['Risk_Level'] = pd.cut(risk_df['Churn_Prob'], bins=bins, labels=labels)\n\n# Plot risk distribution\nrisk_counts = risk_df['Risk_Level'].value_counts().reindex(labels)\nplt.figure(figsize=(6,4))\nsns.barplot(x=risk_counts.index, y=risk_counts.values, palette=\"Reds\")\nplt.title(\"Customer Risk Segmentation\")\nplt.ylabel(\"Number of Customers\")\nplt.show()\n\n\n# ---------------------------\n# Limitations & Next Steps (Optional Visual)\n# ---------------------------\n\n# Visualize churn vs key driver (e.g., IsActiveMember)\nplt.figure(figsize=(6,4))\nsns.countplot(x='ISACTIVE_S', hue=y_test, data=X_test.join(pd.Series(y_test, name='Churned')), palette=\"Set2\")\nplt.title(\"Churn by Active Member Status\")\nplt.xlabel(\"Is Active Member\")\nplt.ylabel(\"Count\")\nplt.legend(title='Churned', labels=['No', 'Yes'])\nplt.show()\n\n# Another view: Churn by Geography\nplt.figure(figsize=(6,4))\nsns.countplot(x='GEOGRAPHY_ENCODED', hue=y_test, data=X_test.join(pd.Series(y_test, name='Churned')), palette=\"Set1\")\nplt.title(\"Churn by Geography\")\nplt.xlabel(\"Geography\")\nplt.ylabel(\"Count\")\nplt.legend(title='Churned', labels=['No', 'Yes'])\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a16ff3a7-b359-4b6d-8f91-824fa01ec52b",
   "metadata": {
    "language": "python",
    "name": "AccuracyRiskBuckets"
   },
   "outputs": [],
   "source": "# Prepare test_df with predictions and risk levels\ntest_df = X_test.copy()\ntest_df['Actual'] = y_test\ntest_df['Predicted'] = y_pred\ntest_df['Correct'] = test_df['Actual'] == test_df['Predicted']\ntest_df['Churn_Prob'] = y_prob\n\n# Define risk bins\nbins = [0, 0.3, 0.6, 1]\nlabels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\ntest_df['Risk_Level'] = pd.cut(test_df['Churn_Prob'], bins=bins, labels=labels)\n\n# Aggregate counts of correct/incorrect by risk level\nrisk_counts = test_df.groupby(['Risk_Level', 'Correct']).size().unstack(fill_value=0)\n\n# Ensure consistent column order\nrisk_counts = risk_counts.reindex(columns=[True, False], fill_value=0)\nrisk_counts.columns = [\"Correct\", \"Incorrect\"]\n\n# Convert to percentages for labeling\nrisk_pct = risk_counts.div(risk_counts.sum(axis=1), axis=0) * 100\n\n# Plot\nplt.figure(figsize=(8,5))\nax = risk_counts.plot(kind='bar', stacked=True, \n                      color=['green', 'red'], alpha=0.85, figsize=(8,5))\n\nplt.xlabel(\"Risk Level\")\nplt.ylabel(\"Number of Predictions\")\nplt.title(\"Prediction Accuracy by Client Churn Risk Level\")\n\n# Add percentage labels on each bar segment\nfor i, (idx, row) in enumerate(risk_counts.iterrows()):\n    total = row.sum()\n    correct = row['Correct']\n    incorrect = row['Incorrect']\n    \n    # Position labels in the middle of each bar segment\n    if correct > 0:\n        ax.text(i, correct/2, f\"{risk_pct.loc[idx, 'Correct']:.1f}%\", \n                ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n\n    if incorrect > 0:\n        ax.text(i, correct + incorrect/2, \n                f\"{risk_pct.loc[idx, 'Incorrect']:.1f}%\", \n                ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n\nplt.xticks(rotation=0)\nplt.legend([\"Correct\", \"Incorrect\"], title=\"Prediction\")\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a41262fa-efc6-471a-9d43-8e453d2e2718",
   "metadata": {
    "language": "python",
    "name": "ShapValuesWaterfall"
   },
   "outputs": [],
   "source": "# Define risk bins\nbins = [0, 0.3, 0.6, 1]\nlabels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\ntest_df['Risk_Level'] = pd.cut(test_df['Churn_Prob'], bins=bins, labels=labels)\n\n# Mapping for the chart\nfeature_name_map = {\n    \"AGE_S\": \"Customer Age\",\n    \"PRODUCTCOUNT_S\": \"Number of Bank Products\",\n    \"GENDER_ENCODED\": \"Gender\",\n    \"ISACTIVE_S\": \"Account Active\",\n    \"CREDITSCORE_S\": \"Credit Score\",\n    \"ACCOUNTBALANCE_S\": \"Account Balance\",\n    \"GEOGRAPHY_ENCODED\": \"Country / Region\",\n    \"OWNSCREDITCARD_S\": \"Has Credit Card\",\n    \"SALARYESTIMATED_S\": \"Estimated Salary\",\n    \"GRADE_S\": \"Customer Tier\"\n}\n\n# Convert feature names in feature_cols to friendly names\nfriendly_feature_names = [feature_name_map.get(f, f) for f in feature_cols]\n\n# SHAP explainer (replace 'model' and 'X_train' with your actual model and training data)\nexplainer = shap.Explainer(model, X_train)\nshap_values = explainer(X_test)\n\n# Get positions in X_test corresponding to the risk levels\nrisk_indices = {}\nfor risk in labels:\n    # Find the indices of test_df for this risk\n    df_indices = test_df[test_df['Risk_Level'] == risk].index.tolist()\n    if df_indices:\n        # Map the first index to the position in X_test\n        pos_in_X_test = X_test.index.get_loc(df_indices[0])\n        risk_indices[risk] = pos_in_X_test\n\n# Plot SHAP waterfall for one client per risk level\nfor risk, pos in risk_indices.items():\n    print(f\"SHAP Waterfall Plot for {risk} Client (Position {pos}):\")\n    \n    plt.figure(figsize=(8, 5))\n    plt.title(f\"{risk} Client\", fontsize=14, fontweight='bold')\n    \n    explanation = shap.Explanation(\n        values=shap_values.values[pos],\n        base_values=shap_values.base_values[pos],\n        data=X_test.iloc[pos],\n        feature_names=friendly_feature_names\n    )\n    \n    shap.waterfall_plot(explanation)\n    plt.tight_layout()\n    plt.show()\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58c76517-f871-4332-b4a0-29028ce2af4a",
   "metadata": {
    "language": "python",
    "name": "PDP",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Define risk bins based on predicted churn probability\nbins = [0, 0.3, 0.6, 1]\nlabels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\ntest_df['Risk_Level'] = pd.cut(test_df['Churn_Prob'], bins=bins, labels=labels)\n\n# Filter high-risk customers\nhigh_risk_df = test_df[test_df['Risk_Level'] == 'High Risk']\n\n# Features for PDP\nfeatures_to_plot = {\n    \"Number of Bank Products\": \"PRODUCTCOUNT_S\",\n    \"Customer Age\": \"AGE_S\",\n    \"Estimated Salary\": \"SALARYESTIMATED_S\"\n}\n\n# Plot partial dependence plots for each feature\nfor title, feature in features_to_plot.items():\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    PartialDependenceDisplay.from_estimator(\n        model,                          # your trained classifier\n        X=high_risk_df[feature_cols],   # only high-risk customers\n        features=[feature],\n        target=1,                       # class 1 = churn\n        ax=ax\n    )\n    \n    ax.set_title(f\"Partial Dependence: {title} vs Churn (High-Risk Customers)\", fontsize=14)\n    plt.tight_layout()\n    plt.show()\n",
   "execution_count": null
  }
 ]
}